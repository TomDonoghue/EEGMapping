{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEGMapping: Group Analysis (Local Data)\n",
    "\n",
    "Words, words, words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.stats import ttest_1samp, ttest_ind, sem, pearsonr\n",
    "\n",
    "from fooof import FOOOF, FOOOFGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom code for this analysis\n",
    "% autoreload 2\n",
    "from plots import *\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Put all general settings here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set whether to save out all the figures\n",
    "SAVE_FIGS = True\n",
    "\n",
    "# Whether to make the data\n",
    "MASKING = True\n",
    "\n",
    "# This controls how much stuff MNE prints out\n",
    "mne.set_log_level(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do's - master version:\n",
    "\n",
    "### Plotting\n",
    "- Figure out how to plot topographies with nan values\n",
    "    - Use MNE masks to select which channels will be plotted\n",
    "        - Suggestion: add a check for which channels have data. Boolean select these channels & positions to pass into plotting.\n",
    "- Reorganize notebook for which parts you have to re run\n",
    "\n",
    "### Quantitative Corrs\n",
    "- Set it up to measure correlation & plot scatterplot\n",
    "    - Generally, for any band, any FOOOF feature \n",
    "        - First: set band & feature, run to see results (finish the generalization: get a scatter plot & corr)\n",
    "        - Also: add to plot Medial -> Lateral (abs)\n",
    "- Collect all R's into corr matrix\n",
    "- Bonus: plot the corr matrix as a colored plot (red/blue). Hint: plt.imshow(matrix). Extra bonus: add a colorbar. \n",
    "        \n",
    "### Per subject analysis\n",
    "- Do the same spatial correlations, per subject, collect distributions of r-vals & p-vals\n",
    "- Plot: boxplots of the R-values, across subjects\n",
    "\n",
    "### Band to Band Correlations\n",
    "- Amplitude-amplitude correlations between bands (across channels)\n",
    "- Plot: corr-matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loading information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lOADING CHANNELS FROM txt\n",
    "save_path = \"C:\\\\Users\\\\abc\\\\EEG-MNE\\\\data\"\n",
    "chan_dat = 'channel_dat.txt'\n",
    "chan_file = os.path.join(save_path, chan_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_dat_num = list(range(3502, 3516))\n",
    "subj_dat_num2 =list(range(3001, 3015))\n",
    "all_subj = subj_dat_num + subj_dat_num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING CHANNELS from raw data\n",
    "# This base path will need updating\n",
    "base_path = 'D:\\\\abc\\\\Documents\\\\Research\\\\PBA_Data'\n",
    "\n",
    "# These should stay the same\n",
    "#subj_dat_fname = '._3001_resampled.set'\n",
    "subj_dat_fname = '3002_resampled.set'\n",
    "full_path = os.path.join(base_path, subj_dat_fname)\n",
    "eeg_dat = mne.io.read_raw_eeglab(full_path, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and set the montage for the data\n",
    "montage = mne.channels.read_montage('standard_1020', eeg_dat.ch_names)\n",
    "eeg_dat.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_dat.plot_sensors(show_names=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract channel positions from a subjects data object\n",
    "pos_new = np.asarray([ch['loc'][:3] for ch in eeg_dat.info['chs']])\n",
    "\n",
    "# Drop stim channel\n",
    "pos_new = pos_new[:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update montage with channel positions\n",
    "montage.pos = pos_new\n",
    "pos = montage.get_pos2d()\n",
    "montage = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DATA SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW Data\n",
    "ret = open('..\\\\data\\\\analysis\\\\rtPB_rest_results.pkl','rb')\n",
    "rtPB_rest_results = pickle.load(ret)\n",
    "\n",
    "ret = open('..\\\\data\\\\analysis\\\\rtPB_trial_results.pkl','rb')\n",
    "rtPB_trial_results = pickle.load(ret)\n",
    "\n",
    "ret = open('..\\\\data\\\\analysis\\\\PBA_rest_results.pkl','rb')\n",
    "PBA_rest_results = pickle.load(ret)\n",
    "\n",
    "ret = open('..\\\\data\\\\analysis\\\\PBA_trial_results.pkl','rb')\n",
    "PBA_trial_results = pickle.load(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slope Data\n",
    "slope_ret = open('..\\\\data\\\\analysis\\\\rtPB_rest_slope_results.pkl','rb')\n",
    "rtPB_rest_slope_results = pickle.load(slope_ret)\n",
    "\n",
    "slope_ret = open('..\\\\data\\\\analysis\\\\rtPB_trial_slope_results.pkl','rb')\n",
    "rtPB_trial_slope_results = pickle.load(slope_ret)\n",
    "\n",
    "slope_ret = open('..\\\\data\\\\analysis\\\\PBA_rest_slope_results.pkl','rb')\n",
    "PBA_rest_slope_results = pickle.load(slope_ret)\n",
    "\n",
    "slope_ret = open('..\\\\data\\\\analysis\\\\PBA_trial_slope_results.pkl','rb')\n",
    "PBA_trial_slope_results = pickle.load(slope_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking\n",
    "## This would allow you to choose an entire region to look over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the channel cluster of interest    \n",
    "pos_ch_cluster = ['Oz','O1','O2','POz','PO3','PO4','PO7','PO8','PO9','PO10']\n",
    "# Check the indices for the channel cluster\n",
    "pos_ch_cluster_index = masking_cluster(pos_ch_cluster,eeg_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "curr_data = \"Combined\"\n",
    "\n",
    "if (curr_data==\"PBA\"):\n",
    "    curr_datasets = [PBA_trial_results, PBA_rest_results]\n",
    "elif (curr_data==\"rtPB\"):\n",
    "    curr_datasets = [rtPB_trial_results, rtPB_rest_results]\n",
    "elif (curr_data==\"Combined\"):\n",
    "    comb_rest = combine_groups(rtPB_rest_results, PBA_rest_results)\n",
    "    comb_trial = combine_groups(rtPB_trial_results, PBA_trial_results)\n",
    "    curr_datasets = [comb_trial, comb_rest]\n",
    "else:\n",
    "    print(\"The dataset you have specified does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bands = [\"alpha\", \"beta\", \"theta\"]\n",
    "feats = [\"CFS\", \"AMPS\", \"BWS\"]\n",
    "\n",
    "for band in bands:\n",
    "    for feat_in, feat in enumerate(feats):\n",
    "        outputs = []\n",
    "        for dataset in curr_datasets:\n",
    "            #masked_data = np.take(dataset[band], indices=pos_ch_cluster_index,  axis=2 )\n",
    "            masked_data = dataset[band]\n",
    "            if (curr_data == \"Combined\"):\n",
    "                masked_feat_in = masked_data[:,:,feat_in]\n",
    "                outputs.append(masked_feat_in)\n",
    "            else:\n",
    "                masked_feat_in = masked_data[:,:,:,feat_in]\n",
    "                masked_feat_in_first = masked_feat_in[:,0,:]\n",
    "                outputs.append(masked_feat_in_first)\n",
    "        title = curr_data + \" \" + band\n",
    "        feature = feat\n",
    "        plot_comp(title, feature, outputs[0],outputs[1], save_fig=SAVE_FIGS)\n",
    "        save_figure(SAVE_FIGS, title +\"_\" + feature + \"_across_state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Across STATE slope plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "curr_data = \"Combined\"\n",
    "\n",
    "if (curr_data==\"PBA\"):\n",
    "    curr_datasets = [PBA_trial_slope_results, PBA_rest_slope_results]\n",
    "elif (curr_data==\"rtPB\"):\n",
    "    curr_datasets = [rtPB_trial_slope_results, rtPB_rest_slope_results]\n",
    "elif (curr_data==\"Combined\"):\n",
    "    slope_comb_rest = combine_slope_groups(rtPB_rest_slope_results, PBA_rest_slope_results)\n",
    "    slope_comb_trial = combine_slope_groups(rtPB_trial_slope_results, PBA_trial_slope_results)\n",
    "    curr_datasets = [slope_comb_trial, slope_comb_rest]\n",
    "else:\n",
    "    print(\"The dataset you have specified does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feats = [\"Offset\", \"Slope\"]\n",
    "\n",
    "for feat_in, feat in enumerate(feats):\n",
    "    outputs = []\n",
    "    for dataset in curr_datasets:\n",
    "        #masked_data = np.take(dataset, indices=pos_ch_cluster_index,  axis=2 )\n",
    "        masked_data = dataset\n",
    "        if (curr_data == \"Combined\"):\n",
    "            masked_feat_in = masked_data[:,:,feat_in]\n",
    "            outputs.append(masked_feat_in)\n",
    "        else:\n",
    "            masked_feat_in = masked_data[:,:,:,feat_in]\n",
    "            masked_feat_in_first = masked_feat_in[:,0,:]\n",
    "            outputs.append(masked_feat_in_first)\n",
    "    title = curr_data \n",
    "    feature = feat\n",
    "    plot_comp(title, feature, outputs[0],outputs[1], save_fig=SAVE_FIGS)\n",
    "    save_figure(SAVE_FIGS, title +\"_\" + feature + \"_across_state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparrison across blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PBA_across_corr_trial = run_dict_across_blocks('PBA', PBA_trial_results, pos_ch_cluster_index, True)\n",
    "rtPB_across_corr_trial = run_dict_across_blocks('rtPB', rtPB_trial_results, pos_ch_cluster_index, True)\n",
    "\n",
    "\n",
    "PBA_across_slope_corr_trial = run_array_across_blocks('PBA', PBA_trial_slope_results, pos_ch_cluster_index, ['Off', 'Sl'], True)\n",
    "rtPB_across_slope_corr_trial = run_array_across_blocks('rtPB', rtPB_trial_slope_results, pos_ch_cluster_index, ['Off', 'Sl'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPOPLOTS and SLOPE TOPOPLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make topos, for each state, within and between datasets, for all features and bands\n",
    "\n",
    "spatial_corr_trial = make_topos([PBA_trial_results, rtPB_trial_results], state= \"Trial\", eeg_dat_info=eeg_dat.info, pos=pos)\n",
    "spatial_corr_rest = make_topos([PBA_rest_results, rtPB_rest_results],state = \"Rest\", eeg_dat_info=eeg_dat.info, pos=pos)\n",
    "spatial_slope_corr_trial = make_topos([PBA_trial_slope_results, rtPB_trial_slope_results], state = \"Trial\", eeg_dat_info=eeg_dat.info, pos=pos)\n",
    "spatial_slope_corr_trial = make_topos([PBA_trial_slope_results, rtPB_trial_slope_results], state = \"Trial\", eeg_dat_info=eeg_dat.info, pos=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Correlations Between Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = group_bands.keys()\n",
    "d_corrm = pd.DataFrame(index=index, columns=index, dtype = float)\n",
    "#Dataframe for correlaton matrix\n",
    "for band in group_bands:\n",
    "    data1 = group_bands[band][:,features[feature]]\n",
    "    for band2 in group_bands:\n",
    "        data2 = group_bands[band2][:,features[feature]]\n",
    "        masked_arr1=mask_nan_array(data1)\n",
    "        masked_arr2=mask_nan_array(data2)\n",
    "        corr_val = pearsonr(data1, data2)[0]\n",
    "        d_corrm.loc[band, band2] = corr_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_corrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_corrm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(topo_dat, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(d_corrm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
